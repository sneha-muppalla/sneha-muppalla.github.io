<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Your Name</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <main class="container">

    <h1 class="name">Sneha Muppalla</h1>
    <p class="email-link">
        <a href="mailto:smuppalla06@berkeley.edu">smuppalla06[at]berkeley[dot]edu</a>
    </p>
    <p class="intro">
        Hello Hello! I’m Sneha, studying a dual degree in EECS and Business under the UC Berkeley M.E.T. program. I build vision systems that blend machine learning, physics, and perception to help people see and understand the world more deeply.
    </p>
    

    <div class="social-links">
      <a href="https://github.com/yourusername" target="_blank">github</a> ·
      <a href="https://www.linkedin.com/in/sneha-muppalla-13b068282/" target="_blank">linkedin</a> ·
      <a href="https://huggingface.co/flying101" target="_blank">huggingface</a> ·
      <a href="film.html" target="_blank">film</a> ·
      <a href="https://youtube.com" target="_blank">paper readings</a> 
    </div>

    <section class="publications">
      <h2>Work</h2>
      <p class="bio">
        I’m interested in physical reasoning, generative modeling, and how visual intelligence can move beyond pattern recognition and towards true understanding. My goal is to bridge technology and storytelling — creating machines that expand how we experience presence, reality, and meaning.
      </p>
      <ul>
        <li>
            <a href="https://arxiv.org/pdf/2310.03827" target="_blank">
              Integrating Audio-Visual Features for Multimodal Deepfake Detection
            </a><br>
            Sneha Muppalla, Shan Jia, Siwei Lyu<br>
            <em>IEEE MIT URTC, 2023</em>
          </li>
      </ul>
    </section>

  </main>
</body>
</html>
